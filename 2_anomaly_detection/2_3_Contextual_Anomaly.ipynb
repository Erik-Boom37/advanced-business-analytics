{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Density Based Clustering\n",
    "# DBSCAN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short for Density-Based Spatial Clustering of Applications with Noise, is the most popular density-based clustering method. We attempt to capture our intuition that a cluster is a region of the data space where there are lots of points, surrounded by a region where there are few points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to identify dense regions, which can be measured by the number of objects close to a given point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:  \n",
    "**Epsilon (Œµ):** Is the radius of neighborhood around a point x. It is called called the Œµ ‚àí neighborhood of x.  \n",
    "**Minimum points (MinPts):** Is the minimum number of neighbors within Œµ radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any point x in the dataset, with a neighbor count greater than or equal to MinPts, is marked as a core point. We say that x is border point, if the number of its neighbors is less than MinPts, but it belongs to the\n",
    "Œµ ‚àí neighborhood of some core point xi. Finally, if a point is neither a core nor a border point, then it is called a noise point or anomalous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/ad10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of clusters does not need to be known a priori.\n",
    "- Recovers much more flexible cluster shapes than K-means, which can\n",
    "only find spherical clusters.\n",
    "- Intrinsically finds and labels outliers as such, making it a great solution for anomaly detection.\n",
    "- It works with any distance function. (e.g. \"euclidean\", \"manhattan\", \"jaccard\", and \"levenshtein\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datasets/sensor_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 6])\n",
    "plt.scatter(dataset['0'], dataset['1'], s=30, alpha=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would it work with K-means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters = 2)\n",
    "clusters = model.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 6])\n",
    "plt.scatter(dataset['0'], dataset['1'], s=30, alpha=0.9, c=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't look correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see with DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=4) #radius and min_core_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = dbscan.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute DBSCAN we‚Äôll go point by point and check if it is a core point or not. If it is a core point we will create a new cluster, then search through all of its neighbors. We‚Äôll add the neighborhoods of all these points to the cluster. If one of the points is a core point as well, it‚Äôs neighborhood will be added to our search. This will continue until we cannot reach anymore points. Then we‚Äôll move on to the next point that we haven‚Äôt visited/labeled yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 6])\n",
    "plt.scatter(dataset['0'], dataset['1'], s=30, alpha=0.9, c=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we generated 2D data, we can plot it and color the points according to the cluster assignments generated by our DBSCAN model. The first step is to join the cluster results back to the original data. Please note: DBSCAN scrambles the row order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/sigmas.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = int(round(len(dataset)*(1-.954),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = []\n",
    "for e in np.arange(0.1, 1, 0.01):\n",
    "    for m in range(1,10):\n",
    "        model = DBSCAN(eps=e, min_samples = m)\n",
    "        clusters = model.fit_predict(X_scaled)\n",
    "        unique, counts = np.unique(clusters, return_counts=True)\n",
    "        anomalies.append((e,m,counts[0]))\n",
    "grid_table = pd.DataFrame(anomalies)\n",
    "grid_table.columns = ['eps','min_neigh','noise']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3ùúé  interva or 2sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_table_exp = grid_table[grid_table.noise < expected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 6])\n",
    "sns.kdeplot(grid_table_exp.eps, grid_table_exp.min_neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Affinity Propagation\n",
    "- Mean Shift\n",
    "- Spectral Clustering\n",
    "- Agglomerative Clustering\n",
    "- HDBSCAN  \n",
    "[Here](https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Contextual Anomalies  \n",
    "#### (Conditional Outliers)\n",
    "<img src=\"../img/contextual.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These type of anomalies occur when a record is only considered anomalous when it is compared within the context of other **metainformation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spatial  \n",
    "The records in the dataset include features which identify locational information for the record. \n",
    "- Graph  \n",
    "The records are related to other records as per some graph structure\n",
    "- Sequential  \n",
    "The records can be considered as a sequence within one another.\n",
    "- Profile  \n",
    "The records can be clustered within profiles that may not have\n",
    "explicit temporal or spatial contextualities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contextual anomalies are considered in applications where the dataset has a combination of\n",
    "**observational** attributes and **behaviour** attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time requires a pre-processing step to determine what the contexts actually are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalies on test responding\n",
    "\n",
    "Values are not outside the normal global range but are abnormal compared to the expected time to respond.\n",
    "Also depends on the type of respondent and the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple sclerosis test in an app\n",
    "It is mainly important to analyze all the features involved in every test taken by a person, and it is straightforward thinking that not all tasks are with full concentration because the nature of the tool, is an app, and we might expect the people taking the test can get distracted by some random reason.\n",
    "\n",
    "The main objective here is to analyze any pattern related to the time in milliseconds a participant spend on responding every visual task, the test goes for 90 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datasets/ms_experiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12, 6])\n",
    "plt.scatter(dataset['trial'], dataset['response_ms'], s=10, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population of Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} Data points distribuited among {} Participants'.format(\n",
    "    len(dataset), len(dataset.userId.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the score variable as the number of correct answers on every test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the patients MS (Multiple Sclerosis) and HC (Health Control)\n",
    "df_ms = dataset[dataset['ms']==1]\n",
    "df_hc = dataset[dataset['ms']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Patients on MS group: {}\\nPatients on HC group: {}'.format(\n",
    "    len(df_ms.userId.unique()),len(df_hc.userId.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16, 8])\n",
    "sns.kdeplot(dataset[dataset['ms']==1]['correct.answers'], color='red', label='MS')\n",
    "sns.kdeplot(dataset[dataset['ms']==0]['correct.answers'], color='blue', label='HC')\n",
    "plt.title('Scores Distribution MS and HC Groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/ms1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/ms2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/ms3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/ms4.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
